{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PICK ONE ################\n",
    "#dataroot = \"/scratch/<BU user name>/img_align_celeba/\" # if on SCC\n",
    "dataroot = \"../score_sde_dev/img_align_celeba/\" # if on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os, math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm_class\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from model import UNet\n",
    "\n",
    "# The CelebA dataset contains 40 binary attribute labels for each image\n",
    "attributes = ['5_o_Clock_Shadow', 'Arched_Eyebrows', \n",
    " 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', \n",
    " 'Big_Lips', 'Big_Nose', 'Black_Hair', \n",
    " 'Blond_Hair', 'Blurry', 'Brown_Hair', \n",
    " 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', \n",
    " 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', \n",
    " 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', \n",
    " 'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', \n",
    " 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', \n",
    " 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    " 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', \n",
    " 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', \n",
    " 'Young']\n",
    "\n",
    "def set_random_seed(seed=999):\n",
    "    # Set random seed for reproducibility\n",
    "    print(\"Random Seed: \", seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        '''Initialize the dataset.'''\n",
    "        self.transform = transform\n",
    "        self.root = dataroot\n",
    "        self.attr_txt = dataroot + 'list_attr_celeba.txt'\n",
    "        self._parse()\n",
    "    \n",
    "    def _parse(self):\n",
    "        '''\n",
    "        Parse the celeba text file.\n",
    "        Pupulate the following private variables:\n",
    "         - self.ys: A list of 1D tensors with 40 binary attribute labels.\n",
    "         - self.im_paths: A list of strings (image paths).\n",
    "        '''\n",
    "        self.im_paths = [] # list of jpeg filenames \n",
    "        self.ys = []       # list of attribute labels\n",
    "        \n",
    "        def _to_binary(lst):\n",
    "            return torch.tensor([0 if lab == '-1' else 1 for lab in lst])\n",
    "            \n",
    "        with open(self.attr_txt) as f:\n",
    "            for line in f:\n",
    "                assert len(line.strip().split()) == 41\n",
    "                fl = line.strip().split()\n",
    "                if fl[0][-4:] == '.jpg': # if not header\n",
    "                    self.im_paths.append(self.root + fl[0]) # jpeg filename\n",
    "                    self.ys.append(_to_binary(fl[1:]))      # 1D tensor of 40 binary attributes\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''Return length of the dataset.'''\n",
    "        return len(self.ys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Return the (image, attributes) tuple.\n",
    "        This function gets called when you index the dataset.\n",
    "        '''\n",
    "        def img_load(index):\n",
    "            imraw = Image.open(self.im_paths[index])\n",
    "            im = self.transform(imraw)\n",
    "            return im\n",
    "\n",
    "        target = self.ys[index]\n",
    "        return img_load(index), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    ''' \n",
    "    Implements the Diffusion process,\n",
    "    including both training and sampling.\n",
    "    '''\n",
    "    def __init__(self, num_timesteps=1000, beta_start=1e-4, beta_end=0.02, img_size=64, device = 'cuda'):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = torch.linspace(beta_start,beta_end,num_timesteps).to(device)\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "    def get_noisy_image(self, x_0, t):\n",
    "        '''\n",
    "        This function is only used for training.\n",
    "        '''     \n",
    "        \n",
    "        eps = torch.randn_like(x_0).to(self.device)\n",
    "        alpha_t = self.alpha[t]\n",
    "        alpha_bar_t = self.alpha_bar[t]\n",
    "        x_t = torch.sqrt(alpha_bar_t)[:,None,None,None] * x_0 + torch.sqrt(1 - alpha_bar_t)[:,None,None,None] * eps\n",
    "        return (x_t, eps)\n",
    "    def sample(self, model, n, y=None):\n",
    "        '''\n",
    "        This function is used  to generate images.\n",
    "        '''\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            T = self.num_timesteps\n",
    "            H = self.img_size\n",
    "            W = self.img_size\n",
    "            x_T = torch.randn(n, 3, H, W, device=self.device)\n",
    "            for k in range(T):\n",
    "                t = T-k-1\n",
    "                if t == (T-1):\n",
    "                  x_t = x_T\n",
    "                \n",
    "                epsilon = model(x_t, (torch.ones(n)*t).long().to(self.device), y)\n",
    "                \n",
    "                mu = (1/torch.sqrt(self.alpha[t]))*(x_t - self.beta[t]*epsilon/torch.sqrt(1-self.alpha_bar[t]))\n",
    "                if t>0:\n",
    "                  x_t = torch.randn_like(mu, device=self.device)*torch.sqrt(self.beta[t]) + mu\n",
    "            x=x_t\n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x\n",
    "    \n",
    "def show_images(images, **kwargs):\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "    grid = torchvision.utils.make_grid(images, **kwargs)\n",
    "    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    '''\n",
    "    This class implements the Expontial Moving Average (EMA) for model weights.\n",
    "    Only used for evaluation.\n",
    "    Using the EMA averaged model increases the quality of generated images.\n",
    "    '''\n",
    "    def __init__(self, beta=0.995):\n",
    "        '''\n",
    "        beta is a hyperparameter.\n",
    "        New model weights = beta * (old model weights) + \n",
    "                            (1 - beta) * (new model weights)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def step_ema(self, ma_model, current_model):\n",
    "        '''\n",
    "        ma_model: the averaged model we will use for evaluation\n",
    "        current_model: The model being explicitly trained\n",
    "        This function updates the weights of ma_model. Return None.\n",
    "        '''\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        '''Private function used to update individual parameters.'''\n",
    "        return old * self.beta + (1 - self.beta) * new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will resize to 64 x 64 for this assignment\n",
    "image_size = 64\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "weight_decay = 0.00001 # (L2 penalty)\n",
    "\n",
    "# Transform used for training\n",
    "train_transform = transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                    (0.5, 0.5, 0.5)),\n",
    "                           ])\n",
    "\n",
    "# Make the dataset\n",
    "dataset = CelebADataset(transform=train_transform)\n",
    "# print(type(dataset))\n",
    "\n",
    "# index of the binary attribute for gender\n",
    "gender_index = attributes.index('Male')\n",
    "\n",
    "# Run on TPU\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate denoising autoencoder\n",
    "model = UNet().to(device)\n",
    "\n",
    "# ema_model is the averaged model that we'll use for sampling\n",
    "ema_model = deepcopy(model)\n",
    "\n",
    "# ema is the helper for updaing EMA weights\n",
    "ema = EMA()\n",
    "\n",
    "# Dataloader\n",
    "trainloader = torch.utils.data.DataLoader(dataset, drop_last=True,  batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "# Mixed precision floating point arithmetic can speed up training on some GPUs\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Diffusion wrapper\n",
    "diffusion = Diffusion(img_size=image_size, device=device)\n",
    "\n",
    "for epoch in range(10): # jtcheck 10\n",
    "    pbar = tqdm_class(trainloader)\n",
    "    count =0\n",
    "    for images, y in pbar:\n",
    "        y = y[:,gender_index].view(-1).cuda()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            images = images.to(device)\n",
    "            \n",
    "\n",
    "            t = torch.randint(low=1, high=diffusion.num_timesteps, size=(batch_size,)).cuda()\n",
    "            x_t, noise = diffusion.get_noisy_image(images, t)\n",
    "            predicted_noise = model(x_t, t, y)\n",
    "\n",
    "            mse_loss = nn.MSELoss()\n",
    "            loss = mse_loss(predicted_noise, noise)\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        pbar.set_postfix(MSE=loss.item(), LR=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # update EMA model. First epoch of training is too noisy, \n",
    "        # so we only do this after the first epoch\n",
    "        if epoch > 0:\n",
    "            ema.step_ema(ema_model, model)\n",
    "        \n",
    "    if epoch == 0:\n",
    "        ema_model = deepcopy(model)\n",
    "\n",
    "    set_random_seed() # set random seed to generate the same style face. This is handy for comparing across epochs.\n",
    "    # n is number of images you want to generate\n",
    "    sampled_images = diffusion.sample(ema_model, n=8, y=torch.tensor([0,0,0,0,1,1,1,1]).cuda())\n",
    "    \n",
    "   \n",
    "    show_images(sampled_images)\n",
    "    \n",
    "    \n",
    "torch.save((ema_model.state_dict(), model.state_dict()), 'ddpm.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-based SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functools\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "  Returns The standard deviation.\n",
    "  \"\"\"    \n",
    "  t = torch.tensor(t, device=device)\n",
    "  # print(t.shape)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "     returns the vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "sigma =  25.0 #@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Define the loss function (double click to expand or collapse)\n",
    "\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x)\n",
    "  \n",
    "  std = marginal_prob_std(random_t)\n",
    "\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t)\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95678d8fea0444ce9b33eda256f7665b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12136/1361517498.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import tqdm.notebook\n",
    "\n",
    "device = 'cuda'\n",
    "# score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = torch.nn.DataParallel(UNet(marginal_prob_std = marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "n_epochs =   50#\n",
    "## size of a mini-batch\n",
    "batch_size =  32 #\n",
    "## learning rate\n",
    "lr = 1e-4  #\n",
    " \n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, drop_last=True,  batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "tqdm_epoch = tqdm.notebook.trange(1) # jtcheck 50\n",
    "for epoch in tqdm_epoch:\n",
    "  avg_loss = 0.\n",
    "  num_items = 0\n",
    "  for x, y in trainloader:\n",
    "    x = x.to(device)   \n",
    "    # print(x.shape)\n",
    "    loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item() * x.shape[0]\n",
    "    num_items += x.shape[0]\n",
    "  # Print the averaged training loss so far.\n",
    "  tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  torch.save(score_model.state_dict(), 'ckpt.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
